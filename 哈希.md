#### 哈希
+ 哈希法又称散列法，相应的表称为哈希表

#### 基本思想
```
首先在元素的关键字k和元素的存储位置p之间建立一个对应关系f，使得p=f(k)，f称为哈希函数。
创建哈希表时，把关键字为k的元素直接存入地址为f(k)的单元；
以后当查找关键字为k的元素时，再利用哈希函数计算出该元素的存储位置p=f(k)，从而达到按关键字直接存取元素的目的。
```
#### 哈希冲突

```
当关键字集合很大时，关键字值不同的元素可能会映象到哈希表的同一地址上，即k1≠k2，但H（k1）=H（k2），这种现象称为冲突，此时称k1和k2为同义词。
实际中，冲突是不可避免的，只能通过改进哈希函数的性能来减少冲突。
```
+ 一致性哈希
```
一致性哈希算法在1997年由麻省理工学院提出的一种分布式哈希（DHT）实现算法，
设计目标是为了解决因特网中的热点(Hot spot)问题，初衷和CARP十分类似。
一致性哈希修正了CARP使用的简单哈希算法带来的问题，使得分布式哈希（DHT）可以在P2P环境中真正得到应用。 
```
+ 一致性hash算法提出了在动态变化的cache环境中，判断哈希算法好坏的四个定义：
```
1、平衡性(Balance)：

平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。
很多哈希算法都能够满足这一条件。 

2、单调性(Monotonicity)：
单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。
哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。 

3、分散性(Spread)：
在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。
当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，
最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。
这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。
分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。 

4、负载(Load)：
负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。
在分布式集群中，对机器的添加删除，或者机器故障后自动脱离集群这些操作是分布式集群管理最基本的功能。
如果采用常用的hash(object)%N算法，那么在有机器添加或者删除后，很多原有的数据就无法找到了，这样严重的违反了单调性原则。接下来主要讲解一下一致性哈希算法是如何设计的。

```
+ 散列函数
```
为了避免散列函数生成的值不是均匀分布，有一个比较好的散列函数可以使用。
在该散列函数中涉及数据中所有的字符，并且一般可以分布的很好,
它计算的是0到KeySize-1进行求和Key[KeySize-i-1]*(37^i);

```
#### 装填因子
```
装填因子是指所有关键子填充哈希表后饱和的程度，它等于 == 哈希表中的记录数/哈希表的长度
装填因子是哈希表装满程度的标记因子。值越大，填入表中的数据元素越多，产生冲突的可能性越大。
```

#### 哈希函数构造
构造哈希函数的目标是使得到的哈希地址尽可能均匀地分布在n个连续内存单元地址上，同时使计算过程
尽可能简单达到尽可能高的时间效率

####  构造原则
```
①函数本身便于计算；
②计算出来的地址分布均匀，即对任一关键字k，f(k)对应不同地址的概率相等，目的是尽可能减少冲突。

```
```
1 直接定址法

公式：f(key)=a*key+b （a,b都是常数）。

适合查找表较小且连续的情况。
优点：简单、均匀，不会产生冲突；

* 缺点：需要知道关键字的分布，现实中不常用。
----------------------------------------------------------------------------------
2 数字分析法
* 如果事先知道关键字集合，并且每个关键字的位数比哈希表的地址码位数多时，
可以从关键字中选出分布较均匀的若干位，构成哈希地址。

例如，有80个记录，关键字为8位十进制整数d1d2d3…d7d8，如哈希表长取100，则哈希表的地址空间为：00~99。
假设经过分析，各关键字中d4和d7的取值分布较均匀，则哈希函数为：h(key)=h(d1d2d3…d7d8)=d4d7。
例如，h(81346532)=43，h(81301367)=06。相反，假设经过分析，各关键字中d1和d8的取值分布极不均匀，d1都等于5，
d8都等于2，此时，如果哈希函数为：h(key)=h(d1d2d3…d7d8)=d1d8，则所有关键字的地址码都是52，显然不可取。

* 适用于关键字较长的情况
----------------------------------------------------------------------------------
3 平方取中法
当无法确定关键字中哪几位分布较均匀时，可以先求出关键字的平方值，然后按需要取平方值的中间几位作为哈希地址。
这是因为：平方后中间几位和关键字中每一位都相关，故不同关键字会以较高的概率产生不同的哈希地址。

* 适合用于不知道关键词分布，且位数不长的情况。

例：我们把英文字母在字母表中的位置序号作为该英文字母的内部编码。
例如K的内部编码为11，E的内部编码为05，Y的内部编码为25，A的内部编码为01, B的内部编码为02。
由此组成关键字“KEYA”的内部代码为11052501，同理我们可以得到关键字“KYAB”、“AKEY”、“BKEY”的内部编码。
之后对关键字进行平方运算后，取出第7到第9位作为该关键字哈希地址，如图所示。

关键字	内部编码	内部编码的平方值	H(k)关键字的哈希地址
KEYA	11050201	122157778355001	778
KYAB	11250102	126564795010404	795
AKEY	01110525	001233265775625	265
BKEY	02110525	004454315775625	315
----------------------------------------------------------------------------------
4 分段叠加法

这种方法是按哈希表地址位数将关键字分成位数相等的几部分（最后一部分可以较短），然后将这几部分相加，舍弃最高进位后的结果就是该关键字的哈希地址。

具体方法有折叠法与移位法。

移位法是将分割后的每部分低位对齐相加，折叠法是从一端向另一端沿分割界来回折叠（奇数段为正序，偶数段为倒序），然后将各段相加。
例如：key=12360324711202065,哈希表长度为1000，则应把关键字分成3位一段，在此舍去最低的两位65，分别进行移位叠加和折叠叠加，求得哈希地址为105和907，如图8.24所示。
1  2  3		1  2  3
6  0  3		3  0  6
2  4  7		2  4  7
1  1  2		2  1  1
+）0  2  0    +）0  2  0
——————— ———————
1  1  0  5      9  0  7
（a）移位叠加    (b)折叠叠加


*适用于不知道关键字分布，且位数较长的情况
----------------------------------------------------------------------------------
5 除留余数法
假设哈希表长为m，p为小于等于m的最大素数，则哈希函数为h（k）=k % p，其中%为模p取余运算。

例如，已知待散列元素为（18，75，60，43，54，90，46），表长m=10，p=7，则有
h(18)=18 % 7=4      h(75)=75 % 7=5      h(60)=60 % 7=4
h(43)=43 % 7=1      h(54)=54 % 7=5      h(90)=90 % 7=6        h(46)=46 % 7=4
此时冲突较多。为减少冲突，可取较大的m值和p值，如m=p=13，结果如下：
h(18)=18 % 13=5    h(75)=75 % 13=10    h(60)=60 % 13=8 
h(43)=43 % 13=4    h(54)=54 % 13=2     h(90)=90 % 13=12       h(46)=46 % 13=7
此时没有冲突，如图所示：
0    1      2      3     4     5     6     7     8      9     10    11    12
 	        	54	         	43	   18	 	       46	    60	 	        75	 	        90
6 伪随机数法

采用一个伪随机函数做哈希函数，即h(key)=random(key)。
```
+ 判断性能时通常需要考虑5个因素
```
在实际应用中，应根据具体情况，灵活采用不同的方法，并用实际数据测试它的性能，以便做出正确判定。

通常应考虑以下五个因素：
计算哈希函数所需时间（简单）。
关键字的长度。
哈希表大小。
关键字分布情况。
记录查找频率。

```
####  解决哈希冲突的方法  （4种）
通过构造性能良好的哈希函数，可以减少冲突，但一般不可能完全避免冲突，因此解决冲突是哈希法的另一个关键问题。
创建哈希表和查找哈希表都会遇到冲突，两种情况下解决冲突的方法应该一致。
下面以创建哈希表为例，说明解决冲突的方法。

常用的解决冲突方法有以下四种：??

```
1 开放定址法（再散列法）

其基本思想是：当关键字key的哈希地址p=H（key）出现冲突时，以p为基础，产生另一个哈希地址p1，如果p1仍然冲突，
再以p为基础，产生另一个哈希地址p2，…，直到找出一个不冲突的哈希地址pi ，将相应元素存入其中。

这种方法有一个通用的再散列函数形式：
          Hi=（H（key）+di）% m   i=1，2，…，n
其中H（key）为哈希函数，m为表长，di称为增量序列。增量序列的取值方式不同，相应的再散列方式也不同。

主要有以下三种：

①线性探测
dii=1，2，3，…，m-1
这种方法的特点是：冲突发生时，顺序查看表中下一单元，直到找出一个空单元或查遍全表

②二次探测
di=12，-12，22，-22，…，k2，-k2   ( k<=m/2 )
这种方法的特点是：冲突发生时，在表的左右进行跳跃式探测，比较灵活。

③伪随机探测
di=伪随机数序列。
具体实现时，应建立一个伪随机数发生器，（如i=(i+p) % m），并给定一个随机数做起点。但查询时需要设置和插入时相同的随机种子。

从上述例子可以看出，线性探测再散列容易产生“二次聚集”，即在处理同义词的冲突时又导致非同义词的冲突。
例如，当表中i, i+1 ,i+2三个单元已满时，下一个哈希地址为i, 或i+1 ,或i+2，或i+3的元素，都将填入i+3这同一个单元，而这四个元素并非同义词。

线性探测的优点是：只要哈希表不满，就一定能找到一个不冲突的哈希地址，而二次探测再散列和伪随机探测再散列则不一定。
------------------------------------------------------------------------------------------------------------------
2 再哈希法
这种方法是同时构造多个不同的哈希函数：
Hi=RH1（key）  i=1，2，…，k
当哈希地址Hi=RH1（key）发生冲突时，再计算Hi=RH2（key）…，遇到冲突就重新采用一个散列函数计算新的存储位置，直到冲突不再产生。这种方法不易产生聚集，但增加了计算时间。

------------------------------------------------------------------------------------------------------------------
3 链地址法

将所有关键字的同义词记录在一个单链表中，在散列表中只存储所有同义词表的头指针.
这种方法的基本思想是将所有哈希地址为i的元素构成一个称为同义词链的单链表，并将单链表的头指针存在哈希表的第i个单元中，
因而查找、插入和删除主要在同义词链中进行。

*链地址法适用于经常进行插入和删除的情况。

例如，已知一组关键字（32，40，36，53，16，46，71，27，42，24，49，64），哈希表长度为13，
哈希函数为：H（key）= key % 13，则用链地址法处理冲突的结果如图所示：
0
1 -> 40 -> 27 -> 53
2
3 -> 16 -> 42
4
5
6 -> 32 -> 71
7 -> 46
8
9
10 -> 36 -> 49
11 -> 24
12 -> 64

```
+ 计算平均查找长度
```
处理冲突的方法                 查找成功时               查找失败时

线性探测法                  1/2 * (1 + 1/(1-a) )        1/2 * (1 + 1/(1-a)^2 )
二次探测法和双哈希法        -1/a * ln(1-a)             1/(1-a)
链地址法                    1+ a/2                     a + a^(-e)
```

+ 例子
假设散列表的长度是13，散列函数为H(K) = k % 13，
给定的关键字序列为{32， 14， 23， 01， 42， 20， 45， 27， 55， 24， 10， 53}。
分别画出用线性探测法和拉链法解决冲突时构造的哈希表，并求出在等概率情况下，
这两种方法的查找成功和查找不成功的平均查找长度。
```
1 线性探测法：
0  1  2  3  4  5  6  7  8  9  10  11  12 
   14 01 42 27 55 32 20 45 53 23  24  10
    1  2  1  4  3  1  1  3  9  1   1   3         <-比较次数
    
查找成功时的查找次数等于插入元素时的比较次数,查找成功的平均查找长度为：
ASL =（1+2+1+4+3+1+1+3+9+1+1+3)/12 = 2.5
    
查找不成功时的查找次数：第n个位置不成功时的比较次数为，
第n个位置到第1个没有数据位置的距离：如第0个位置取值为1，第1个位置取值为2.

查找不成功（也就是再插入一个新的元素需要试选几次，即每个位置距离下一个空格位置的距离的平均）
的平均查找次数为：ASL=（1+2+3+4+5+6+7+8+9+10+11+12）/ 13 = 91/13

---------------------------------------------------------------------------
2 链地址法

次数  1    2    3    4
.......................
0
1 -> 14 -> 1 -> 27 ->53
2
3 -> 42 -> 55
4

5
6 -> 32 -> 45
7 -> 20
8
9
10 -> 23 -> 10
11 -> 24
12

查找成功时的平均查找长度：ASL = (1*6+2*4+3*1+4*1)/12 = 7/4

查找不成功（各个链表长度的平均）时的平均查找长度：ASL = (4+2+2+1+2+1)/13 = 12/13

注意：查找成功时，分母为哈希表元素个数，查找不成功时，分母为哈希表长度

```
+  哈希算法在信息安全中主要应用在？
(1)    文件校验
(2)    数字签名
(3)    鉴权协议

#### STL中的哈希表 unordered_map
+ 基本原理
```
用于存储由关键值 (Key Value，以下称为Key 值) 和映射值 (Mapped Value，以下称为映射值) 组成的元素，并且允许根据其 Key 值快速检索各个元素。 
在 unordered_map 容器中，Key 值通常用来唯一标识元素，映射值是与该 Key 值关联内容的对象。Key 值与映射值的类型可能不同。 
在 unordered_map 内部，元素没有按照其 Key 值与映射值的任何顺序进行排序 ，而是根据它们的 Hash 值组织成桶，允许它们通过其 Key 值直接快速访问单个元素（通常具有常数等级的平均时间复杂度）。 
```
```
查找效率高，时间复杂度为常数级别 O(1)， 而额外空间复杂度则要高出许多。
所以对于需要高效率查询的情况，使用unordered_map容器。

而如果对内存大小比较敏感或者数据存储要求有序的话，则可以用map容器。
```
+ 容器属性
```
1 关联性 
关联容器中的元素的参考地址指的是其 Key 值，而不是他们在容器中的绝对地址；
2 无序性 
无序容器使用 Hash 表来组织元素，这些 Hash 表允许无序容器通过 Key 值快速访问元素；
3 映射 
每个元素将一个 Key 值与映射值关联起来，Key 值用于标识其主要内容是映射值的元素；
4 唯一关键值 
容器中不存在同时拥有相同 Key 值的两个元素；
5 分配器感知 
map 容器使用分配器对象动态处理其存储需求。
```
+ 常用函数
```
(1) bucket
定位元素所在的桶，返回key值为输入参数k的元素所在的桶号。
桶是容器内部hash表中的一个槽，槽中的元素根据key值分配元素。桶号的编号从0到（bucket_count -1）
桶中单个元素可以通过unorderd_map::begin 和unordered_map::end返回的范围迭代器进行访问。

for (auto& x : mymap3) {
        std::cout << "Element [" << x.first << ":" << x.second << "]";
        // 返回元素所在桶号
        std::cout << " is in bucket #" << mymap3.bucket(x.first) << std::endl;
    }
    
(2) count
    count(1)
   搜索容器中 Key 值为输入参数 k 的元素，并返回找到元素的数量。
   由于 unordered_map 容器不允许存在重复的 Key 值，这说明如果容器中存在具有该 Key 值的 元素，则该函数返回 1，否则返回 0。

(3) clear
    清除map中所有元素
    erase
    删除map中指定位置的元素
    insert
    在map指定位置添加pair类型的元素
    find
    获取map中元素的迭代器
    begin,end
    map的正向迭代器的起始位置与终点位置
```
+ 程序实例
```
```
+ 和 map, hash_map 的区别
```
1. 头文件
map： 
#include <map>
hash_map： 
#include <hash_map>
unordered_map： 
#include <unordered_map>

2. 内部实现机理
map： 
map 内部实现了一个红黑树，该结构具有自动排序的功能，因此map内部的所有元素都是有序的，红黑树的每一个节点都代表着map的一个元素，因此，对于map进行的查找，删除，添加等一系列的操作都相当于是对红黑树进行这样的操作，故红黑树的效率决定了map的效率，map只需要提供比较函数（一般为小于函数）即可完成比较；

hash_map： 
hash_map 需要提供 hash 函数，以及等于函数；

unordered_map： 
unordered_map 内部实现了一个 Hash 表，所以其元素的排列顺序是杂乱无序的。

3. 优缺点
map： 
优点： 
有序性：这是map结构最大的优点，其元素的有序性在很多应用中都会简化很多的操作；
红黑树，内部实现一个红黑书使得 map 的很多操作在 log n 的时间复杂度下就可以实现，因此效率非常的高；
缺点： 
空间占用率高，因为 map 内部实现了红黑树，虽然提高了运行效率，但是因为每一个节点都需要额外保存父节点，子节点以及红/黑性质，使得每一个节点都占用大量的空间；
适用于具有顺序要求的问题；

hash_map： 
优点： 
hash_map 查找速度会比map快，而且查找速度基本和数据量大小无关，属于常数级别（但不能说一定比 map 的 log n 级别快，因为 hash 函数本身也有耗时）；
缺点： 
空间占用多，如果对内存使用很严格，需要认真考虑是否使用 hash_map ；特别是当 hash_map 对象特别多时，更加难以控制；
适用于对效率要求较高的环境；

unordered_map： 
优点： 
内部实现了 Hash 表，所以查找速度很快；
缺点： 
Hash 表的建立比较比较费时；
适用于查找问题；
```
